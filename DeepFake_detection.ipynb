{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS9JaXv79sL9",
        "outputId": "ba372389-121c-4fb4-e2cf-19918bca0bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (1000, 40, 500)\n",
            "Training labels shape: (1000,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess_audio(audio_file_path, max_length=500):\n",
        "    try:\n",
        "\n",
        "        audio, _ = librosa.load(audio_file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n",
        "        if mfccs.shape[1] < max_length:\n",
        "            mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_length]\n",
        "        mfccs_normalized = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
        "        return mfccs_normalized\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while processing file: {audio_file_path}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_data(directory):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for label, folder in enumerate(['Real', 'Fake']):\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            features = preprocess_audio(file_path)\n",
        "            if features is not None:\n",
        "                data.append(features)\n",
        "                labels.append(label)\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/deepfake/Training\"\n",
        "\n",
        "\n",
        "train_dir = os.path.join(dataset_dir)\n",
        "x_train, y_train = load_data(train_dir)\n",
        "\n",
        "#val_dir = os.path.join(dataset_dir, \"validation\")\n",
        "#x_val, y_val = load_data(val_dir)\n",
        "\n",
        "# Check the shapes of the loaded data\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "#print(\"Validation data shape:\", x_val.shape)\n",
        "#print(\"Validation labels shape:\", y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(40, 500)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    LSTM(units=64, return_sequences=True),\n",
        "    LSTM(units=64),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dropout(rate=0.5),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "428DeOHB-HdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "a_gnMpnV_w86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qr0kNJ__7JG",
        "outputId": "4807c598-dcd3-4d89-f47f-f1b68c655b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 7s 29ms/step - loss: 0.5251 - accuracy: 0.7480\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.2827 - accuracy: 0.9050\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.2500 - accuracy: 0.9180\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.1968 - accuracy: 0.9290\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.1523 - accuracy: 0.9470\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1538 - accuracy: 0.9500\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 1s 42ms/step - loss: 0.1266 - accuracy: 0.9570\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0861 - accuracy: 0.9690\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0574 - accuracy: 0.9810\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0542 - accuracy: 0.9820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_train, y_train)\n",
        "print(\"Training Loss:\", loss)\n",
        "print(\"Training Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPYkgWPOAApg",
        "outputId": "a9a2a602-94b3-4065-80ed-1b2f43e7b735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 10ms/step - loss: 0.0353 - accuracy: 0.9890\n",
            "Training Loss: 0.035285353660583496\n",
            "Training Accuracy: 0.9890000224113464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_audio(audio_file_path, max_length=500):\n",
        "    try:\n",
        "        # Load audio file\n",
        "        audio, _ = librosa.load(audio_file_path, sr=16000)\n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n",
        "        # Pad or trim MFCCs to ensure a consistent shape\n",
        "        if mfccs.shape[1] < max_length:\n",
        "            mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_length]\n",
        "        # Normalize MFCC features\n",
        "        mfccs_normalized = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
        "        return mfccs_normalized\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while processing file: {audio_file_path}\")\n",
        "        return None\n",
        "\n",
        "def predict(audio_file_path, model, threshold=0.5):\n",
        "    # Preprocess the audio file\n",
        "    processed_audio = preprocess_audio(audio_file_path)\n",
        "    if processed_audio is not None:\n",
        "        # Reshape the input for the model\n",
        "        input_data = np.expand_dims(processed_audio, axis=0)\n",
        "        # Make predictions\n",
        "        prediction = model.predict(input_data)\n",
        "        # Determine class based on threshold\n",
        "        if prediction >= threshold:\n",
        "            return \"Fake\"\n",
        "        else:\n",
        "            return \"Real\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "audio_file_path = \"/content/drive/MyDrive/deepfake/Testing/Fake/musk-to-obama.wav\"\n",
        "prediction = predict(audio_file_path, model)\n",
        "print(\"Prediction:\", prediction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOBFfgMCAYOY",
        "outputId": "06c4fe71-5659-49a8-e023-c52b1f896efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n",
            "Prediction: Real\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XsdMympAw8R",
        "outputId": "bf388509-a5fd-4e43-d363-21cd1a720ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joi7ghQDFtTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}